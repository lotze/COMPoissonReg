%\VignetteIndexEntry{A Vignette for the COMPoissonReg Package OLD}
%\VignetteAuthor{Andrew and ?}
%\VignetteKeyword{R}
%\VignetteKeyword{package}
%\VignetteKeyword{vignette}
%\VignetteKeyword{LaTeX}
%\VignetteEngine{R.rsp::tex}

\documentclass[10pt]{article}
\usepackage{common}

\title{A Vignette for the COMPoissonReg Package}
\author{Andrew and ?}
\date{Version 0.8.0}

\begin{document}
\maketitle




(TBD: mention that, if possible, we will try to discuss in terms of the ZICMP model, for which all the other models are special cases.)

\begin{itemize*}
\item Demonstrate functions for the CMP and ZICMP distributions. This should include \code{d}, \code{p}, \code{q}, and \code{r} functions, \code{e} and \code{v}, and the normalizing constant.
\item To do this, we maximize the log-likelihood function in optim
\item We provide some hooks to control optim
\item Formula interface
\item We might need a section on handling large counts in the regression model. This is especially where numerical problems tend to occur.
\item \citet{Eddelbuettel2013} for Rcpp ...
\item For normalizing constant, can we somehow give lower bounds so we don't need to start summing from 0? Is it possible to use root-finding here since the bounds aren't quite invertible themselves?
\item Maybe give code in Section~\ref{sec:normconst} to change the options for tolerances?
\end{itemize*}




\paragraph{TBD}
\begin{itemize*}
\item A good way to motivate adding these complications is to show some plots of $f(y) = \lambda^y / (y!)^\nu$.
\item We could potentially compute score and FIM via the Lindsey and Merch trick and avoid numerical derivatives. Can we use our bound above to help guide the truncation there? (The approximation method might not be straightforward to connect). Do we want to deal with this now?
\item We need to explain / demonstrate ymax and the other options somewhere around here.
\end{itemize*}

\subsection{Computation of Functions involving $Z$}
Derivatives of $\log Z(\lambda, \nu)$ are needed to compute expected values, score functions, and covariance matrices needed by \pkg{COMPoissonReg}. Using the hybrid procedure described at the beginning of Section~\ref{sec:normconst} to compute $\log Z(\lambda, \nu)$, we make use of the numerical differentiation in the following ways.

The gradient of the log-likelihood \eqref{eqn:likelihood} is needed in \code{optim} during likelihood maximization.  The Hessian of the log-likelihood is used to estimate $\Var(\hat{\btheta})$ given a solution $\hat{\btheta} = (\vec{\beta}, \vec{\gamma}, \vec{\zeta})$ from \code{optim}. The expected value $\E(Y) = \lambda \frac{\partial}{\partial \lambda} \log Z(\lambda, \nu)$ and variance $\Var(Y) = \text{TBD}$ of $Y \sim \text{CMP}(\lambda, \nu)$ may be of interest to package users as well.

Suppose $Y \sim \text{CMP}(\lambda, \nu)$. We use numerical differentiation to compute the expected value
%
\begin{align}
\E(Y) &= \lambda \frac{\partial}{\partial \lambda} \log Z(\lambda, \nu), \nonumber \\
&= \lim_{\epsilon \downarrow 0} \lambda \frac{\log Z(\lambda + \epsilon, \nu) - \log Z(\lambda, \nu)}{\epsilon} \nonumber \\
&\approx \frac{\log Z(\lambda + h, \nu) - \log Z(\lambda, \nu) }{h / \lambda},
\label{eqn:fwdderiv}
\end{align}
%
given a small $h > 0$. Forward differentiation respects the boundary $\lambda = 0$.

 SimilarThe gradient and Hessian are computed 

The gradient and Hessian of the log-likelihood \eqref{} involve first and second derivatives of $\log Z(\lambda, \nu)$. 


How are they used?

The gradient and Hessian of $\log Z(\lambda, \nu)$ are also needed to compute the Fisher Information Matrix for the CMP and ZICMP models; see the expressions in \citet{SellersRaim2016}. We may compute them in a similar manner as \eqref{eqn:fwdderiv}. For a given function $g : \mathbb{R}^k \rightarrow \mathbb{R}$, we may compute the $j$th entry of the gradient as
%
\begin{align*}
\nabla_j g(\vec{x})
\approx \frac{ g(\vec{x} + h \vec{e}_j) - g(\vec{x}) }{h},
\end{align*}
%
and the $(j,l)$th entry of the Hessian as
%
\begin{align*}
\nabla^2_{jl} g(\vec{x})
\approx \frac{g(\vec{x} + h \vec{e}_j + h \vec{e}_l) -
g(\vec{x} + h \vec{e}_j) -
g(\vec{x} + h \vec{e}_l) +
g(\vec{x})}{h^2}.
\end{align*}
%
Here, $\vec{e}_1, \ldots, \vec{e}_k$ represent the columns of a $k \times k$ identity matrix.

We make use of various derivatives of $\log Z(\lambda, \nu)$ as well, especially to compute the Fisher Information matrix \citep{SellersRaim2016}. These derivatives can be obtained as closed-form infinite sums, but a very large number of terms may be needed to get a reasonable approximation. (TBD: The issue appears potentially worse in some of the derivatives than in $\log Z(\lambda, \nu)$, but I did not investigate this in detail. Also, we no long use this part of the code, and just use the Hessian instead of the FIM).


\begin{comment}
\section{Delete This}
To include a PDF vignette that is compiled from a plain LaTeX file,
all you need is the LaTeX file with LaTeX comments containing
meta directives to R such that it will be listed as a vignette in the
package.
The LaTeX-based vignette file should be placed in the
\code{vignettes/} directory of your package.  If your LaTeX file
includes other files such as figure files, these should also be
located in the \file{vignettes/}.
For instance, this PDF document was compiled from LaTeX file:
%
\begin{enumerate}
\item \code{vignettes/R\_packages-LaTeX\_vignettes.ltx}
\end{enumerate}
%
which contains the following meta directives at the top of the file:
%
\begin{CodeInput}[numbers=left,xleftmargin=5mm]
%\VignetteIndexEntry{R packages: LaTeX vignettes}
%\VignetteEngine{R.rsp::tex}
%\VignetteKeyword{R}
%\VignetteKeyword{package}
%\VignetteKeyword{vignette}
%\VignetteKeyword{LaTeX}
\end{CodeInput}
%
Here I choose filename extension \code{*.ltx}, which is a lesser known LaTeX
filename extension, because if one uses \code{*.tex}, then \code{R CMD check}
will give a NOTE complaining that the file is a stray file that should not be
part of the built package.

Also, the above first two entries are required whereas the keyword
entries are optional.  Note also that the
%\code{\%{\bs}VignetteIndexEntry\{\}} controls the title shown in R's
help indices as well as in online package respositories such as CRAN. 

As for any type of (non-Sweave) package vignette, don't forget to specify:
%
\begin{CodeInput}
Suggests: R.rsp
VignetteBuilder: R.rsp
\end{CodeInput}
%
in your package's DESCRIPTION file.  That's all it takes to include a
LaTeX file that will be compiled into a PDF vignette as part of the
package build.
\end{comment}

\bibliographystyle{plainnat}
\bibliography{references}
%\input{references.bbl}













\appendix

\clearpage


\section{Adaptive Computation of $Z$ (TBD: Obsolete)}
Let $h(x) := x \log \lambda - \nu \log \Gamma(x+1)$ denote the unnormalized CMP log-density and $\delta > 0$ be a small prespecified number. In this section, we will discuss a procedure to find an $M$ such that 
%
\begin{align}
\exp\{ h(x) \} < \delta, \quad \text{for all $x \geq M$}.
\label{eqn:diff}
\end{align}
%
To do this, we will establish that $h(x)$ is a concave function of $x \in \mathbb{R}$. We have first and second derivatives
%
\begin{align*}
&h'(x) = \log \lambda - \nu \frac{\partial}{\partial x} \log \Gamma(x+1)
= \log \lambda - \nu \psi(x+1), \\
&h''(x) = - \nu \frac{\partial^2}{\partial x^2} \log \Gamma(x+1).
\end{align*}
%
where $\psi(x) = \frac{\partial}{\partial x} \log \Gamma(x)$ is the digamma function. It is well-known that $\log \Gamma(\cdot)$ is a convex function (TBD: cite?), so $h(x)$ has a negative second derivative and is therefore a concave function of $x$. Then $h(x)$ has a unique maximum $x^*$ such that $h'(x) = 0$ Therefore, $h'(x)$ will be positive for $x < x^*$, zero for $x = x^*$, and negative for $x > x^*$. Consequently, $h(x)$ will be decreasing for $x > x^*$ so that \eqref{eqn:diff} can be satisfied.

Our strategy will be to compute $Z^{(M)}(\lambda, \nu)$ in three phases: first, increase $M$ until $h'(M) \leq 0$ is satisfied; second, increase $M$ until $h(M) < \log \delta$ is satisfied; finally, increase $M$ until \eqref{eqn:adaptive-log-scale} is satisfied. To facilitate computing $h'(x)$, we recall the well-known property that $\psi(x+1) = \psi(x) + \frac{1}{x}$, so that
%
\begin{align*}
\psi(M+1) = \psi(M) + \frac{1}{M} = \cdots = \psi(1) + \sum_{r=1}^M \frac{1}{r},
\end{align*}
%
where $-\psi(1) = \gamma \approx 0.5772157$ is the Euler-Mascheroni constant. We now state the adaptive computation as Algorithm~\ref{alg:adaptz}.

\begin{algorithm}
\caption{An adaptive computation of the series in $Z(\lambda, \nu)$.}
\label{alg:adaptz}
\begin{algorithmic}
\Function{AdaptiveZ}{$\lambda, \nu, \delta, \epsilon$}
\State $z \leftarrow 0$,
$h(y) \leftarrow \infty$,
$\psi \leftarrow -\gamma$,
$y \leftarrow 0$,
$h'(y) \leftarrow \infty$
\While{$h'(y) > 0$}
\State $h(y) \leftarrow y \log \lambda - \nu \log \Gamma(y+1)$
\State $z \leftarrow z + \exp\{h(y)\}$
\State $\psi \leftarrow \psi + 1 / (y+1)$
\State $h'(y) \leftarrow \log \lambda - \nu \psi$
\State $y \leftarrow y + 1$
\EndWhile

\While{$h(y) > \log \delta$}
\State $h(y) \leftarrow y \log \lambda - \nu \log \Gamma(y+1)$
\State $z \leftarrow z + \exp\{ h(y) \}$
\State $y \leftarrow y + 1$
\EndWhile

\While{$M \leq \lambda^{1/\nu} e - 1$}
\State $h(y) \leftarrow y \log \lambda - \nu \log \Gamma(y+1)$
\State $z \leftarrow z + \exp\{ h(y) \}$
\State $y \leftarrow y + 1$
\EndWhile

\State Compute $\log \Delta_M$ according to Section~\ref{sec:quantify-error}
\While{$\log \Delta_M - \log z \geq \log \epsilon$}
\State $h(y) \leftarrow y \log \lambda - \nu \log \Gamma(y+1)$
\State $z \leftarrow z + \exp\{ h(y) \}$
\State $y \leftarrow y + 1$
\State Recompute $\log \Delta_M$
\EndWhile

\State \Return $z$
\EndFunction
\end{algorithmic}
\end{algorithm}
%
To address issue A3, we can employ a ``hybrid'' method to compute $\log Z(\lambda, \nu)$. Given some threshold $\kappa > 0$, we return $\log \tilde{Z}(\lambda, \nu)$ computed via \eqref{eqn:z-approx} if $\lambda^{-1/\nu} < \kappa$, and $\log \tilde{Z}(\lambda, \nu)$ computed via Algorithm~\ref{alg:adaptz} otherwise.

\section{OLD Introduction}
\label{sec:old-intro}
TBD
\begin{enumerate*}
\item This vignette gives an overview of the COMPoissonReg package.

\item The COMPoissonReg package fits COM-Poisson (CMP) and Zero-Inflated COM-Poisson (ZICMP) regression models.

\item A brief review of relevant literature (and whatever we want to mention).
%
\begin{enumerate*}
\item The distribution was first described in \citet{ConwayMaxwell1962}.
\item It found a renewed interest in count modeling in \citet{ShmueliEtAl2005} because of its ability to capture both over- and underdispersion.
\item Other interesting count distributions include Negative Binomial, Generalized Poisson, \ldots
\item CMP was explored for use in count regression models in \citet{SellersShmueli2010}.
\item ZICMP was explored for zero-inflated count regression in \citet{SellersRaim2016}.
\item Works by \citet{Huang2017} and \citet{RibeiroEtAl2020} reparameterize CMP to be more interpretable in terms of the mean.
\item Some other interesting extensions to CMP include the multivariate CMP distribution \citep{SellersMorrisBalakrishnan2016}, count processes based on CMP \citep{ZhuEtAl2017}, zero- and $k$-inflated CMP \citep{AroraChagantySellers2021}, the Conway Maxwell Binomial (CMB) regression model (TBD: cite), the Conway Maxwell Multinomial (CMM) regression model \citep{KadaneWang2018,MorrisRaimSellers2020}, \ldots
\end{enumerate*}


\item Normalizing constant.
%
\begin{enumerate*}
\item \citet{ShmueliEtAl2005} seem to be the first ones to address this. Others listed here are more sophisticated and build on this initial work. We don't use them in the software, but they may be interesting to readers.
\item \citet{GillispieGreen2015} 
\item \citet{DalyGaunt2016}
\item \citet{BrooksEtAl2017} apparently also has an adaptive method for computing the CMP normalizing constant.
\item \citet{GauntEtAl2019}
\end{enumerate*}

\item Related software packages.
%
\begin{enumerate*}
\item The \code{compoisson} R package \citep{compoisson} implements CMP distribution functions. It had been on CRAN since 2011, but was deprecated on 2/16/2020.
\item The \code{CompGLM} R package \citep{CompGLM} implements CMP regression. It had been on CRAN since 2014, but was deprecated on 10/16/2019.
\item CMP regression is supported in the SAS COUNTREG procedure \citep{SASProcCountreg2018}
\item The \code{mpcmp} R package \citep{FungEtAl2020} implements the mean-parameterized CMP regression described in \citet{Huang2017}.
\item The \code{cmpreg} R package \citep{cmpreg} implements the CMP parameterization from \citet{RibeiroEtAl2020}.
\item The \code{combayes} R package \citep{combayes} implements Bayesian CMP analysis.
\item The \code{multicmp} R package \citep{multicmp} supports the multivariate CMP distribution \citep{SellersMorrisBalakrishnan2016}.
\item The \code{COMMultReg} R package \citep{COMMultReg} supports the CMM regression model.
\end{enumerate*}

\item In Section~\ref{sec:model}, we briefly review the model. In Section~\ref{sec:normconst}, we discuss computation of the normalizing constant, \ldots
\end{enumerate*}

\end{document}
